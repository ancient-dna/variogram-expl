<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="ipynb_website:version" content="0.9.2" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" type="text/css" href="../css/jt.css">
<link rel="stylesheet" type="text/css" href="../css/toc2.css">
<link href="../site_libs/jqueryui-1.11.4/jquery-ui.css">
<link rel="stylesheet" href="../site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<link rel="stylesheet" href="../site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.9.1/jquery-ui.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<link rel="stylesheet"
      href="../site_libs/highlight/textmate.css"
      type="text/css" />
<script src="../site_libs/highlight/highlight.js"></script>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>
<script src="../js/toc2.js"></script>
<script src="../js/docs.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
<script>
    MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
        },
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["TeX"],
            styles: {
                scale: 110,
                ".MathJax_Display": {
                    "font-size": "110%",
                }
            }
        }
    });
</script>
<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');
  // mark it active
  menuAnchor.parent().addClass('active');
  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>
<div class="container-fluid main-container">
<!-- tabsets -->
<script src="../site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>
<title>Variogram exploration</title>
<style type = "text/css">
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
</style>
</head>
<body>
<div tabindex="-1" id="notebook" class="border-box-sizing">
<div class="container" id="notebook-container">
<!-- code folding -->
<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">Variogram exploration</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../license.html">License</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
   <a href="https://github.com/ancient-dna/variogram-expl"> source </a>
</li>
</ul>
      </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Normal-approximations">Normal approximations<a class="anchor-link" href="#Normal-approximations">&#182;</a></h1><p><strong>authors:</strong> Joseph Marcus, Hussein Al-Asadi</p>
<p>Here we explore a computationally efficient Empircal Bayes for modeling low-coverage sequence data. We are uncertain this approach will work but will explore it as it provides a tractable path forward for including read-level emissions in our work.</p>
<h2 id="Generative-model">Generative model<a class="anchor-link" href="#Generative-model">&#182;</a></h2><p>Consider the following generative model for read data in single individual $i$ at SNP $j$. To generate the data first we simulate an allele frequency trajectory under the Wright-Fisher model. We assume our individuals are observed at different time-points stored in a $n$-vector $\mathbf{t}$. Let $\mathbf{x}_{j}$ be a vector of latent allele counts in a single population at these time points. Furthermore, let $\mathbf{f}_{j} = \mathbf{x}_{j} \odot \frac{1}{2N_e}$ be the allele frequencies and $N_e$ be the effective population size. Finally, Let $\mu_j$ be the mean of the process (the starting allele frequency of the Markov Chain). Given these frequencies we sample genotypes in an individual assuming Hardy-Weinberg equilibrium. Finally, given the genotypes we simulate read data which is the count of the derived allele. Here $c_{ij}$ is the total coverage.</p>
<p>$$
\begin{aligned}
\mathbf{f}_j | \mu_j, N_e &amp;\sim WF(\mu_j, N_e) \\
g_{ij} | f_{ij} &amp;\sim Binomial\big(2, f_{ij}\big) \\
y_{ij} | g_{ij} &amp;\sim Binomial\Big(c_{ij}, \frac{g_{ij}}{2}\Big)
\end{aligned}
$$</p>
<p>To motivate the normal approximation used later, we derive the mean and covariance matrix implied by the above model</p>
<p>$$
\begin{aligned}
x_{j,t} | x_{j,t-1}, N_e &amp;\sim Binomial\Big(2N_e, \frac{x_{j,t-1}}{2N_e}\Big) \\
E(x_{j,t}) &amp;= \mu_j \\
Var(x_{j,t}) &amp;= \mu_j(1-\mu_j)\Bigg(1 - \Big(1 - \frac{1}{N_e}\Big)^t \Bigg) \approx \mu_j(1-\mu_j)\big(1-e^{\frac{-t}{2N_e}}\big) \\
\Rightarrow \\
E(f_{j,t}) &amp;= \frac{\mu_j}{2N_e} \\
Var(f_{j,t}) &amp;= \frac{\mu_j(1-\mu_j)\big(1-e^{\frac{-t}{2N_e}}\big)}{2N_e} \approx \frac{\mu_j(1-\mu_j)}{2N_e} t \\
Cov(f_{j,s}, f_{j,t}) &amp;= Cov\big(f_{j,s}, (f_{j,t} - f_{j,s}) + f_{j,s}\big) \\
&amp;= Cov(f_{j,s}, f_{j,t} - f_{j,s}) + Cov(f_{j,s}, f_{j,s}) \\
&amp;= Var(f_{j,s}) \\
&amp;\approx \frac{\mu_j(1-\mu_j)}{2N_e} s
\end{aligned}
$$</p>
<p>Let $\mathbf{T}$ be a $n \times n$ matrix with $\mathbf{T}_{ij} = min(t_i, t_j)$ storing the minimum times between each pair of individuals. We let the variance-covariance matrix $\mathbf{\Sigma} = \frac{\mu_j(1-\mu_j)}{2N_e} \mathbf{T}$</p>
<h2 id="Normal-approximation">Normal approximation<a class="anchor-link" href="#Normal-approximation">&#182;</a></h2><p>Here we consider an approximation to the above generative model where we using normal approximations for each of the conditional distributions. Note that we switch to continuous time as we use a Brownian Motion approximation to the discrete time Wright-Fisher Markov Chain.</p>
<p>$$
\begin{aligned}
\mathbf{f}_j(\mathbf{t}) | \mu_j, N_e &amp;\sim \mathcal{N}\Big(\mu_j, \frac{\mu_j(1-\mu_j)}{2N_e}\mathbf{T}\Big) \\
\mathbf{g}_j | \mathbf{f}_j(\mathbf{t}) &amp;\sim \mathcal{N}\Big(2\mathbf{f}_j(\mathbf{t}), diag\big\{2\mathbf{f}_j(\mathbf{t}) \odot \big(\mathbf{1}-\mathbf{f}_j(\mathbf{t})\big)\big\}\Big) \\
\mathbf{y}_j | \mathbf{g}_j &amp;\sim \mathcal{N}\Bigg(\mathbf{c}_j \odot \frac{\mathbf{g}_j}{2}, diag\Big\{\mathbf{c}_j \odot \frac{\mathbf{g}_j}{2} \odot \Big(\mathbf{1}-\frac{\mathbf{g}_j}{2}\Big)\Big\}\Bigg)
\end{aligned}
$$</p>
<p>If we integrate out $\mathbf{f}_j(\mathbf{t})$</p>
<p>$$
\begin{aligned}
\mathbb{E}(\mathbf{g}_j) &amp;= \mathbb{E}\Big(\mathbb{E}\big(\mathbf{g}_j | \mathbf{f}_j(\mathbf{t})\big)\Big) \\
&amp;= \mathbb{E}\big(2\mathbf{f}_j(\mathbf{t})\big) \\
&amp;= 2\mu_j\mathbf{1} \\
Var(\mathbf{g}_j) &amp;= Var\Big(\mathbb{E}\big(\mathbf{g}_j | \mathbf{f}_j(\mathbf{t})\big)\Big) + \mathbb{E}\Big(Var\big(\mathbf{g}_j | \mathbf{f}_j(\mathbf{t})\big)\Big) \\
&amp;= 4Var\big(\mathbf{f}_j(\mathbf{t})\big) + \mathbb{E}\Big(diag\big\{2\mathbf{f}_j(\mathbf{t}) \odot \big(\mathbf{1}-\mathbf{f}_j(\mathbf{t})\big)\big\}\Big)\\ 
&amp;= 4\frac{\mu_j(1-\mu_j)}{2N_e}\mathbf{T} + diag\Big\{2\mu_j(1-\mu_j)\Big(\mathbf{1}-\frac{\mathbf{t}}{2N_e}\Big)\Big\} \\
&amp;= 4\frac{\mu_j(1-\mu_j)}{2N_e}\mathbf{T} + 2\mu_j(1-\mu_j)\mathbf{I} - \frac{2\mu_j(1-\mu_j)}{2N_e}diag(\mathbf{T}) \\
&amp;= \frac{2\mu_j(1-\mu_j)}{2N_e}\Big(2\mathbf{T} - diag(\mathbf{T})\Big) + 2\mu_j(1-\mu_j)\mathbf{I} \\
&amp;= \frac{\mu_j(1-\mu_j)}{2N_e} \Big(4\mathbf{T} - 2diag(\mathbf{T})\Big) + 2\mu_j(1-\mu_j)\mathbf{I} \\
\end{aligned}
$$</p>
<p>Thus we have</p>
<p>$$
\mathbf{g}_j | \mu_j, N_e \sim \mathcal{N}\Bigg(2\mu_j\mathbf{1}, \frac{\mu_j(1-\mu_j)}{2N_e} \Big(4\mathbf{T} - 2diag(\mathbf{T})\Big) + 2\mu_j(1-\mu_j)\mathbf{I}\Bigg)
$$</p>
<p>$$
\mathbf{y}_j | \mathbf{g}_j \sim \mathcal{N}\Big(\mathbf{c}_j \odot \frac{\mathbf{g}_j}{2}, diag\Big\{\mathbf{c}_j \odot \frac{\mathbf{g}_j}{2} \odot \Big(\mathbf{1}-\frac{\mathbf{g}_j}{2}\Big)\Big\}\Big)
$$</p>
<hr>
<p>Next we can integrate out $\mathbf{g}_j$ to obtain the marginal distribution of $\mathbf{y}_j$ conditional on $\mu_j, N_e$</p>
<p>$$
\begin{aligned}
\mathbb{E}(\mathbf{y}_j) &amp;= \mathbb{E}\big(\mathbb{E}(\mathbf{y}_j | \mathbf{g}_j) \big) \\
&amp;= \mathbf{c}_j \odot \mathbb{E}\Big(\frac{\mathbf{g}_j}{2}\Big) \\
&amp;=\mathbf{c}_j\mu_j \\
Var(\mathbf{y}_j) &amp;= Var\big(\mathbb{E}(\mathbf{y}_j | \mathbf{g}_j)\big) + \mathbb{E}\big(Var(\mathbf{y}_j | \mathbf{g}_j)\big) \\
&amp;= Var\Big(\mathbf{c}_j \odot \frac{\mathbf{g}_j}{2}\Big)\\
&amp;= \frac{\mathbf{c}_j\mathbf{c}^T_j}{4} \odot Var\big(\mathbf{g}_j\big)+ \mathbb{E}\big(Var(\mathbf{y}_j | \mathbf{g}_j)\big) \\
&amp;= \frac{\mathbf{c}_j \mathbf{c}^T_j}{4} \odot \Bigg(\frac{\mu_j(1-\mu_j)}{2N_e} \Big(4\mathbf{T} - 2diag(\mathbf{T})\Big) + 2\mu_j(1-\mu_j)\mathbf{I}\big)\Bigg) + \mathbb{E}\big(Var(\mathbf{y}_j | \mathbf{g}_j)\big) \\
\Rightarrow
\end{aligned}
$$</p>
<p>$$
\begin{aligned}
\mathbb{E}\big(Var(\mathbf{y}_j | \mathbf{g}_j)\big) &amp;= \mathbb{E}\Bigg(diag\Big\{\mathbf{c}_j \odot \frac{\mathbf{g}_j}{2} \odot \Big(\mathbf{1}-\frac{\mathbf{g}_j}{2}\Big)\Big\}\Bigg) \\
\end{aligned}
$$</p>
<p>We can consider each individual separately here thus ...</p>
<p>$$
\begin{aligned}
\mathbb{E}\Big(c_{ij}\frac{g_{ij}}{2}\big(1 - \frac{g_{ij}}{2}\big)\Big) &amp;= c_{ij} \mathbb{E}\Big(\frac{g_{ij}}{2} - \frac{g^2_{ij}}{4}\Big) \\
&amp;= c_{ij}\Big(\frac{1}{2}E(g_{ij}) - \frac{1}{4}E(g^2_{ij})\Big) \\
&amp;= c_{ij}\Big(\frac{1}{2}2\mu_j - \frac{1}{4}\big(Var(g_{ij}) + E(g_{ij})^2\big)\Big) \\
&amp;= c_{ij}\Big(\mu_j - \frac{1}{4}\big(Var(g_{ij}) + 4\mu^2_j\big)\Big) \\
&amp;= c_{ij}\Big(\mu_j(1-\mu_j) - \frac{1}{4}Var(g_{ij}) \Big) \\
&amp;= c_{ij}\Bigg(\mu_j(1-\mu_j) - \frac{1}{4}\Big(\frac{\mu_j(1 - \mu_j)}{2N_e}(4t_i - 2t_i) + 2\mu_j(1-\mu_j) \Big)\Bigg) \\
&amp;= c_{ij}\Bigg(\mu_j(1-\mu_j) - \frac{1}{4}\Big(2\frac{\mu_j(1 - \mu_j)}{2N_e}t_i + 2\mu_j(1-\mu_j) \Big)\Bigg) \\
&amp;= c_{ij}\Bigg(\mu_j(1-\mu_j) - \frac{1}{2}\frac{\mu_j(1 - \mu_j)}{2N_e}t_i - \frac{1}{2}\mu_j(1-\mu_j)\Bigg) \\
&amp;= \frac{c_{ij}}{2}\Bigg(\mu_j(1-\mu_j) - \frac{\mu_j(1 - \mu_j)}{2N_e}t_i \Bigg)
\end{aligned}
$$</p>
<p>Thus our marginal variance is</p>
<p>$$
Var(\mathbf{y}_j) = \frac{\mathbf{c}_j \mathbf{c}^T_j}{4} \odot \Bigg(\frac{\mu_j(1-\mu_j)}{2N_e} \Big(4\mathbf{T} - 2diag(\mathbf{T})\Big) + 2\mu_j(1-\mu_j)\mathbf{I}\big)\Bigg) + \frac{\mathbf{c}_j}{2} \odot \Bigg(\mu_j(1-\mu_j)\mathbf{I} - \frac{\mu_j(1-\mu_j)}{2N_e}diag(\mathbf{T}) \Bigg)
$$</p>
<p>Finally our marginal distribution is</p>
<p>$$
\mathbf{y}_j | \mu_j, N_e \sim \mathcal{N}\Bigg(\mathbf{c}_j\mu_j, \frac{\mathbf{c}_j \mathbf{c}^T_j}{4} \odot \Bigg(\frac{\mu_j(1-\mu_j)}{2N_e} \Big(4\mathbf{T} - 2diag(\mathbf{T})\Big) + 2\mu_j(1-\mu_j)\mathbf{I}\big)\Bigg) + \frac{\mathbf{c}_j}{2} \odot \Bigg(\mu_j(1-\mu_j)\mathbf{I} - \frac{\mu_j(1-\mu_j)}{2N_e}diag(\mathbf{T}) \Bigg) \Bigg)
$$</p>
</div>
</div>
</div>
<hr>
&copy; 2017 Peter Carbonetto &amp; Gao Wang
</div>
</div>
</body>
</html>
