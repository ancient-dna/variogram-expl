{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal approximations\n",
    "\n",
    "**authors:** Joseph Marcus, Hussein Al-Asadi\n",
    "\n",
    "Here we explore a computationally efficient Empircal Bayes for modeling low-coverage sequence data. We are uncertain this approach will work but will explore it as it provides a tractable path forward for including read-level emissions in our work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following generative model for read data in single individual $i$ at SNP $j$. To generate the data first we simulate an allele frequency trajectory under the Wright-Fisher model. We assume our inviduals are observed at different time-points stored in a $n$-vector $\\mathbf{t}$. Let $\\mathbf{f}_j(\\mathbf{t})$ be the latent allele frequencies observed at these time points. Furthermore let $\\mu_j$ be the mean of the process (the starting allele frequency of the Markov Chain) and $N_e$ be the effective population size. Given these frequencies we sample genotypes in an individual assuming Hardy-Weinberg equilibrium. Finally, given the genotypes we simulate read data which is the count of the derived allele. Here $c_{ij}$ is the total coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{f}_j(\\mathbf{t}) | \\mu_j, N_e &\\sim WF(\\mu_j, N_e) \\\\\n",
    "g_{ij} | f_{ij}(t_i) &\\sim Binomial\\big(2, f_{ij}(t_i)\\big) \\\\\n",
    "y_{ij} | g_{ij} &\\sim Binomial\\Big(c_{ij}, \\frac{g_{ij}}{2}\\Big)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider an approximation to the above generative model where we using normal approximations for each of the conditional distributions. \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{f}_j(\\mathbf{t}) | \\mu_j, N_e &\\sim \\mathcal{N}(\\mu_j, \\mathbf{\\Sigma})\\\\\n",
    "\\mathbf{g}_j | \\mathbf{f}_j(\\mathbf{t}) &\\sim \\mathcal{N}\\Big(2\\mathbf{f}_j(\\mathbf{t}), 2diag\\big\\{\\mathbf{f}_j(\\mathbf{t}) \\cdot \\big(\\mathbf{1}-\\mathbf{f}_j(\\mathbf{t})\\big)\\big\\}\\Big) \\\\\n",
    "\\mathbf{y}_j | \\mathbf{g}_j &\\sim \\mathcal{N}\\Bigg(\\mathbf{c}_j \\cdot \\frac{\\mathbf{g}_j}{2}, diag\\Big\\{\\mathbf{c}_j \\cdot \\frac{\\mathbf{g}_j}{2} \\cdot \\Big(\\mathbf{1}-\\frac{\\mathbf{g}_j}{2}\\Big)\\Big\\}\\Bigg)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we integrate out $\\mathbf{f}_j(\\mathbf{t})$ \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}(\\mathbf{g}_j) &= \\mathbb{E}\\Big(\\mathbb{E}\\big(\\mathbf{g}_j | \\mathbf{f}_j(\\mathbf{t})\\big)\\Big) \\\\\n",
    "&= \\mathbb{E}\\big(2\\mathbf{f}_j(\\mathbf{t})\\big) \\\\\n",
    "&= 2\\mu_j\\mathbf{1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(\\mathbf{g}_j) &= Var\\Big(\\mathbb{E}\\big(\\mathbf{g}_j | \\mathbf{f}_j(\\mathbf{t})\\big)\\Big) + \\mathbb{E}\\Big(Var\\big(\\mathbf{g}_j | \\mathbf{f}_j(\\mathbf{t})\\big)\\Big) \\\\\n",
    "&= 4Var\\big(\\mathbf{f}_j(\\mathbf{t})\\big) + \\mathbb{E}\\Big(2diag\\big\\{\\mathbf{f}_j(\\mathbf{t}) \\cdot \\big(\\mathbf{1}-\\mathbf{f}_j(\\mathbf{t})\\big)\\big\\}\\Big)\\\\ \n",
    "&= \\dots \\\\\n",
    "&= \\mu_j(1-\\mu_j)\\big(\\mathbf{\\Sigma} + diag\\{\\mathbf{\\Sigma}\\} + 2\\mathbf{I}\\big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{g}_j | \\mu_j, N_e \\sim \\mathcal{N}\\Big(2\\mu_j\\mathbf{1}, \\mu_j(1-\\mu_j)\\big(\\mathbf{\\Sigma} + diag\\{\\mathbf{\\Sigma}\\} + 2\\mathbf{I}\\big)\\Big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_j | \\mathbf{g}_j \\sim \\mathcal{N}\\Big(\\mathbf{c}_j \\cdot \\frac{\\mathbf{g}_j}{2}, diag\\Big\\{\\mathbf{c}_j \\cdot \\frac{\\mathbf{g}_j}{2} \\cdot \\Big(\\mathbf{1}-\\frac{\\mathbf{g}_j}{2}\\Big)\\Big\\}\\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our idea is to fix the variance in the likelihood ($\\mathbf{y}_j | \\mathbf{g}_j$) by computing an estimate of $\\mathbf{g}_j$ from the data. Let $\\mathbf{\\Lambda}^{(j)} = diag\\Big\\{\\mathbf{c}_j \\cdot \\frac{\\hat{\\mathbf{g}}_j}{2} \\cdot \\Big(\\mathbf{1}-\\frac{\\hat{\\mathbf{g}}_j}{2}\\Big)\\Big\\}$ then we can rewrite the model as\n",
    "\n",
    "$$\n",
    "\\mathbf{g}_j | \\mu, N_e \\sim \\mathcal{N}\\Big(2\\mu_j\\mathbf{1}, \\mu_j(1-\\mu_j)\\big(\\mathbf{\\Sigma} + diag\\{\\mathbf{\\Sigma}\\} + 2\\mathbf{I}\\big)\\Big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_j | \\mathbf{g}_j \\sim \\mathcal{N}\\Big(\\mathbf{c}_j \\cdot \\frac{\\mathbf{g}_j}{2}, \\mathbf{\\Lambda}^{(j)} \\Big)\n",
    "$$\n",
    "\n",
    "to be clear $\\mathbf{\\Lambda}^{(j)}$ is fixed! Next we can integrate out $\\mathbf{g}_j$ to obtain the marginal distribution of $\\mathbf{y}$ conditional on $\\mu_j, N_e$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}(\\mathbf{y}_j) &= \\mathbb{E}\\big(\\mathbb{E}(\\mathbf{y}_j | \\mathbf{g}_j) \\big) \\\\\n",
    "&= \\mathbf{c}_j \\cdot \\mathbb{E}\\Big(\\frac{\\mathbf{g}_j}{2}\\Big) \\\\\n",
    "&=\\mu_j\\mathbf{c}_j \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(\\mathbf{y}_j) &= Var\\big(\\mathbb{E}(\\mathbf{y}_j | \\mathbf{g}_j)\\big) + \\mathbb{E}\\big(Var(\\mathbf{y}_j | \\mathbf{g}_j)\\big) \\\\\n",
    "&= \\mathbf{c}_j Var\\big(\\mathbf{g}_j\\big)\\mathbf{c}^T_j + \\mathbb{E}\\big(Var(\\mathbf{y}_j | \\mathbf{g}_j)\\big) \\\\\n",
    "&= \\mathbf{c}_j\\Big(\\mu_j(1-\\mu_j)\\big(\\mathbf{\\Sigma} + diag\\{\\mathbf{\\Sigma}\\} + 2\\mathbf{I}\\big)\\Big)\\mathbf{c}^T_j + \\mathbf{\\Lambda}^{(j)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus our marginal likelihood for $\\mathbf{y}_j$\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_j | \\mu_j, N_e \\sim \\mathcal{N}\\Bigg(\\mu_j \\mathbf{c}_j, \\mathbf{c}_j\\Big(\\mu_j(1-\\mu_j)\\big(\\mathbf{\\Sigma} + diag\\{\\mathbf{\\Sigma}\\} + 2\\mathbf{I}\\big)\\Big)\\mathbf{c}^T_j + \\mathbf{\\Lambda}^{(j)}\\Bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate $\\mu_j$ and $N_e$ using maximum likelihood and plug them in to the full model to compute the posterior of $\\mathbf{g}_j$ given $\\mathbf{y}_j$ analytically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
